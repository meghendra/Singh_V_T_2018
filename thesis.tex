%        File: VTthesis_template.tex
%     Created: Thu Mar 24 11:00 AM 2016 EDT
% Last Change: Wed Apr 06 02:37 PM 2016 EDT
%      Author: Alan M Lattimer, VT
%
% Instructions for using the document are embedded in the document.  Additionally, there
% are comments at the end of the file that give some suggestions on writing your
% thesis.  To get started you should add VTthesis.cls to your path or keep it in
% the same directory as this file.  In addition to the standard formatting options
% the following options are defined for the VTthesis class:
%  proposal, prelim, doublespace, draft
\documentclass[doublespace,draft]{VTthesis}
% Using the following header instead will create a draft copy of your thesis
%\documentclass[doublespace,draft]{VTthesis}

% The lipsum package is just included to put dummy text in the document in order to demonstrate 
% page headers and table of contents behavior.  You should remove it once you begin 
% writing your actual thesis or dissertation
\usepackage{lipsum}
\usepackage{booktabs}
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\red}[1]{\textbf{\textcolor{red}{#1}}}
% Title of your thesis
\title{Human Behavior Modeling and Calibration in Epidemic Simulations}

% You should include 3-5 keywords, separated by commas
\keywords{Some Keywords, Subject matter, etc.}

% Your name including middle initial
\author{Meghendra Singh}

% Change this to your program, e.g. Physics, Civil Engineering, etc.
\program{Computer Science} 

% Change this to your degree, e.g. Masters of Science, Masters of Art, etc.
\degree{Masters of Science} 

% This should be your defense date
\submitdate{TBD 00, 2018} 

% Committee members. Only have five readers and one chair available
% only use the ones you need and don't include the ones you don't need.
% You can also declare a Co-advisor. If you do, the principal and co-advisors
% will be listed as co-advisors on the title page.  Per the VT ETD standards, 
% you should not include titles or educational qualifications such as PhD or Dr.
% You should however include middle initials if possible.
\principaladvisor{Madhav V. Marathe}
%\coadvisor{Vicente Esparza}
\firstreader{Samarth Swarup}
\secondreader{Anil Vullikanti}
\thirdreader{Tanushree Mitra}
%\fourthreader{Fourth Committee Member}
%\fifthreader{Fifth Committee Member}

% The dedication and acknowledgement pages are optional.  Uncomment to 
% include them in your thesis or dissertation
%\dedication{This is where you put your dedications.}
%\acknowledge{This is where you put your acknowledgments.}

% The abstract is required and should be <=250 words for thesis, <=350 words for disseration
\abstract{
% Give a brief description of your thesis here. Max of 250 words for a master's thesis.
Computational epidemiologists frequently employ large-scale agent-based
simulations of human populations to study disease outbreaks
and assess intervention strategies. The agents used in such simulations
rarely capture the real-world decision-making of human
beings. An absence of realistic agent behavior can undermine the reliability of insights generated by such simulations and might make
them ill-suited for informing public health policies. In this work,
we address this problem by developing a methodology to create
and calibrate an agent decision making model for a large multiagent
simulation, using survey data. Our method optimizes a cost
vector associated with the various behaviors to match the behavior
distributions observed in a detailed survey of human behaviors
during influenza outbreaks. Our approach is a data-driven way of
incorporating decision making for agents in large-scale epidemic
simulations.
}

% The general audience abstract is required. There are currently no word limits.
\abstractgenaud{You are also required as of Spring 2016 to include a general audience abstract.  This should	be geared towards individuals outside of your field that may be reading seeking information about your work. You should avoid language that is particular to your field and clearly define any terms that may have special meaning in your discipline.}

\begin{document}
	% The following lines set up the front matter of your thesis or dissertatin and is required to ensure proper
	% formatting per the VT ETD standards. 
  \frontmatter
  \maketitle
  \tableofcontents

	% The list of figures and tables are now optional per the official ETD standards.  Unless you have a very
	% good reason for removing them, you should leave these lists in the document.  Comment them out to remove
	% them.
	\listoffigures
	\listoftables

	% The following sets up the document for the main part of the thesis or dissertation. Do not comment out or
	% remove this line.
	\mainmatter

	%now go ahead and start writing your thesis
	\chapter{Introduction} \label{ch:introduction}
	Behavior is a crucial aspect of infectious disease outbreak control, as demonstrated most recently by the Ebola outbreak in western Africa and the measles outbreak in the USA. The spread of HIV in parts of Africa also was facilitated by social, economic and behavioral factors \cite{ezzell2000care}. SARS rates fell during the epidemic, partly due to behavioral choices made by individuals which led to a reduction in population contact rates and to rapid hospital attendance by symptomatic individuals \cite{riley2003transmission}. Understanding the interaction of self-initiated individual behavior with disease dynamics is essential while studying epidemic spread through human populations \cite{ferguson2007capturing}. 

    Influenza epidemics in particular, occur annually and place a huge cost upon the society~\cite{meltzer99economic}. Given that, vaccination rates for seasonal influenza tend to be less than 50\% in the USA, other strategies for mitigation of the disease also become very important. Such activities include self-initiated behavioral interventions such as hygienic practices, staying home when sick, avoiding crowded places, and more. Additionally, influenza can often have mild or no symptoms, so only a small fraction of the infected go to hospitals, making it hard to assess the true size of the epidemic. Further, the extent to which people change their behaviors during an influenza outbreak to reduce their susceptibility is not well understood so far. Infectious disease outbreaks also have an associated contagion of information, with people adjusting their behavior based on their perceptions of risk, upon receiving information about the outbreak. Modeling self-initiated human behavior is a very important piece of the puzzle in furthering the understanding of infectious disease epidemics, yet epidemiological models rarely include such models of human behavior. 
    
    There have been only a few attempts to model behavior in a data-driven way for social simulation (see~\cite{pynadath16behavior} for a recent example). Part of the reason for this is the relative paucity of data on behaviors during epidemics. Another crucial issue is development and calibration of behavior models when data \emph{are} indeed available. Computational simulations of epidemics have become quite sophisticated at incorporating multiple sources of data and calibrating disease models~\cite{EG+04}, but the analogous methodology for representing and calibrating behavior models and integrating them with these large-scale simulations is yet to be developed.
    
    Hence, the three main steps for modeling human behavior in epidemic simulations are: collection of human behavioral data during an epidemic, development of a decision making model to drive the behavioral decisions of synthetic individuals in the epidemic simulation and calibration of the decision making model using the collected behavioral data so as to ensure that the behavioral decisions of synthetic individuals (or agents) in the survey match those of the real-world human population. Each of these steps has multiple challenges associated with them. 
    
    First, as people`s behaviors change with time, it is important that the behavioral data be collected as and when any individual's behavior changes while an epidemic spreads through a population. While it might be possible to collect data at this level of granularity for a small set of individuals in a controlled experiment setting, gathering large scale temporally varying behavioral data in an epidemic affected population is by nature infeasible. A more practical approach may be to collect panel data at regular intervals of time, from a representative sample of individuals in a population as the epidemic spreads in the said population. However, most of the time we might only get access to cross-sectional survey data for a representative sample of the population, capturing a summary of the sampled individual`s behaviors during an epidemic, devoid of the temporal variability. Therefore, it is important for the decision making model to be able to use such type of cross-sectional behavioral survey for modeling and calibration purposes. 
    
    Second, agent decision making has traditionally been studied in the domain of reinforcement learning through the formalism of Markov Decision Processes (MDPs) and its extensions. For example, Partially-Observable Markov Decision Processes (POMDPs), Decentralized Markov Decision Processes (Dec-MDPs) and Semi-Markov Decision Processes (SMDPs). These formalisms have been historically designed for single agent environments, with well-defined state, action and reward structures. For example, a robot trying to navigate a path through a maze or balancing a pole placed on top of a cart. Epidemic simulations, on the other hand are large multi-agent environments with ill-defined states, actions and reward structures. Multi-Agent Markov Decision Processes (MMDPs) could potentially be used in this case but the state and action spaces in MMDPs drastically grow as the number of agents increases. Furthermore, in MMDPs agents typically cooperate to optimize a common objective, which makes sense if a group of robots are trying to play as a team to maximize there teams score. Although, a common objective is undefined in an epidemic simulation where each individual`s behavioral decisions are independent of others. Partial-observability and decentralized control further add to the complexity of these formalisms and it becomes computationally intractable to find a joint optimal policy that can be used by all the agents. 
    Lastly, given that an agent decision-making model is in place, we need a method for ensuring that the behaviors generated by this model for each agent match the observed behaviors in the collected survey data. This will help evaluate and calibrate the decision-making model with the collected survey data. This can be looked at as an optimization problem with the objective of minimizing an optimization objective would reduce the difference between the behaviors generated by the decision-making model and those observed in the behavioral survey. 
    
    Taking into account these challenges, we take a phenomenological approach to behavior modeling and calibration. We focus on getting the population-level distributions of behaviors right, and are less concerned with the individual decision-making process and the psychological and cognitive factors that might be involved. The goal here is to be able to simulate populations of behaving agents and to extrapolate the population-level consequences of patterns of behavior. Thus we use one of the simplest Markov decision model i.e., a Markov Decision Process (MDP) to model agent decision making about disease avoidance behaviors in a large scale influenza simulation. Note that the agent decision-making model and the behavior model refer to the same MDP throughout this paper and a single MDP is shared by all agents in the simulation.
    
    \begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/calibrationproc.pdf}
    \caption{The behavior modeling and calibration approach}
    \label{fig:calib-proc}
    \end{figure}
    
    Figure~\ref{fig:calib-proc} gives a high-level overview of the human behavior modeling and calibration process. There are three inputs to the behavior modeling and calibration approach. First, is the Outbreak Survey, which is a cross-sectional survey of Influenza related behaviors, collected from adults across the United States. The survey was designed to gain insights about people’s experience, beliefs and behaviors with respect to Influenza. In this work, we focus on the behaviors adopted by individuals to avoid getting Influenza. We discuss the survey analysis and the different behaviors in detail in chapter~\ref{ch:survey}.
    
    Second, is the Synthetic Population which is statistically equivalent to a real-world population of a particular geographic region in the United States (e.g., Montgomery county, VA). The Synthetic Population captures the demographics and schedules of its real-world counterpart and is used by the epidemic simulator to simulate the spread of a contagion in the corresponding geographic region. A third input is the disease specific parameters, which are once again used by the epidemic simulator for simulating the corresponding disease within the synthetic population. We also map each behavioral action (intervention) discovered in the outbreak survey analysis to its implementation in the epidemic simulation. Deciding to adopt an intervention by an agent may lead to a reduction in the likelihood of the behaving agents getting infected in the epidemic simulation. We discuss the simulation, the synthetic population, disease dynamics models and interventions in detail in chapter~\ref{ch:epi-simulations}. 
    
    The behaviors discovered in the outbreak survey analysis along with some of the disease specific details (e.g., health states in the SEIR Influenza progression model) are used to construct the specifications (i.e., the states, actions and transitions) of the agent Behavior Model (MDP). Within the epidemic simulator, an agent's decision to adopt a set of behaviors is driven by the MDP and the MDP component which drives agent decision making is called the reward function. In this work, we posit that the optimal reward function for the MDP would lead to a close match between the patterns of behavior observed in the simulated and real worlds. To this end we iteratively tune the parameters of the MDP model used in the epidemic simulator in an optimization loop. We call this the process of behavior model calibration and different Optimization algorithms (i.e., Optimizers) lead to different calibration results. We describe the agent-decision making model, the calibration approach and our experiments with three type of Optimization algorithms in detail in chapter~\ref{ch:decision-model}. Subsequently, we report the main results of this study in chapter~\ref{ch:results} and end with conclusions and future work in chapter~\ref{ch:conclusions}.
    
    The unique contribution of this work is bringing together survey data on behavior, a large-scale simulation that is capable of implementing those same behaviors and an agent decision making model. The combination of the three things leads to a more direct calibration method for the behavior models in our work. The survey provides the relative proportions of a sample of the various behaviors in the population. The simulation in-sync with the agent decision making model allows us to determine the probability of agents acting in a particular way due to the infectious disease and information flow dynamics in the population. In combination, we can search the space of rewards associated with the behaviors in the MDP using optimization. This optimization can essentially be thought of as an inverse reinforcement learning problem~\cite{ng00irl} where the optimal rewards would lead to a complete match between the population-level phenomenon. This phenomenon of interest being the distribution of behaviors in the outbreak survey human population and the simulated agent population. Next, we discuss past work in the area of behavior modeling from an agent's perspective and from a public health perspective.

	\chapter{Review of Literature} \label{ch:lit_review}
	Efforts at modeling human behavior and decision-making have a long history in the public health and psychology literature. These approaches generally focus on the within-agent decision-making process, such as the Health Belief Model (HBM)~\cite{rosenstock66hbm}, the Theory of Planned Behavior~\cite{ajzen91tpb}, and the Theory of Reasoned Action~\cite{ajzen80understanding}. These approaches are now also being implemented in computational models~\cite{Durham2012H1N1,orr13health}. The main limitations of these approaches are that the models seem hard to calibrate since some of the parameters appear to be confounded (e.g., perceived risk and perceived severity), and further the data required to infer the parameters of these models are hard to obtain. 

    On the other hand, there are many examples of behavior modeling in computational epidemiology and other domains where behaviors are modeled in a counter-factual or prescriptive way. For example, in a study trying to evaluate whether it is better for people to evacuate or shelter in place after a nuclear detonation~\cite{wein10nuclear,parikh16jaamas}, the authors only have to model the counter-factual scenarios where everyone shelters or everyone evacuates.
    
    Similarly in large-scale simulation studies of flu interventions, modelers generally restrict themselves to assuming that all individuals in the model do the behavior (with some compliance rate). For example, Halloran et al.~\cite{halloran08modeling} studied multiple intervention scenarios in a flu pandemic in the city of Chicago. This work ranked interventions by effectiveness, but did not consider  people's typical behavior during flu epidemics.
    
    In a different context, Singh et al.~\cite{singh16bdi} have used the Belief Desire Intention (BDI) framework to create agents which are embedded into large-scale social simulations. Their approach is more focused on the engineering aspects of the problem, such as the agent architecture, modularity, and the design of the simulation platform, than on calibration of the behaviors. They also focus on explainability of agent decision-making and acceptability to the end-users.
    
    The most relevant recent work is that of Pynadath et al.~\cite{pynadath16behavior}. They used survey data to parametrize a Partially Observable Markov Decision Process (POMDP) model of stay/leave decision-making in a disaster response scenario. They show how to create the states, actions, environment, and rewards for an agent and then train the agent.
    
	\chapter{Outbreak Survey} \label{ch:survey}
	We used data from an epidemiological survey in 2016, aimed at understanding people's experience with the Influenza illness. The survey was administered online by the  Gfk~Group~\cite{wiki:wikigfk} to 2165 participants which constituted a nationally representative sample of the United States population, selected from the KnowledgePanel$^{\textregistered}$. The participants only included adults (people 18 years of age and above) and only included households with at-least one adult occupant. The survey captured demographic information of the participants including age, household income, employment status, education, ethnicity, gender, household and geographic information.
	\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/demographics.png}
    \caption{Demographic distributions of the survey sample}
    \label{fig:demog}
    \end{figure}
	Figure~\ref{fig:demog} shows the distributions of some of these demographics of the surveyed population. The survey also captured respondents' responses about their health behaviors, risk perceptions, vaccine uptake, and information sources for outbreak updates about Influenza. Of particular relevance to this work were the actions taken by respondents to avoid getting influenza (interventions). These interventions are listed below: 
	\begin{enumerate}
	    \item Avoid touching eyes (ATE).
	    \item Avoid touching nose (ATN).
	    \item Avoid touching mouth (ATM).
        \item Wash hands with soap (WHS).
        \item Use hand sanitizers (UHS).
        \item Clean surfaces at home (CSH).
        \item Clean surfaces at work (CSW).
        \item Eat nutritious food (ENF).
        \item Get adequate rest (GAR).
        \item Get recommended vaccine (GRV).
        \item Take preventive medicine e.g. antiviral (TPM).
        \item Use surgical mask to cover nose and mouth (USM).
        \item Avoid contact with people who are sick (ACS).
        \item Avoid crowded places (ACP)
	\end{enumerate}
	\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/avoidancebehaviors.png}
    \caption{Distribution of individual avoidance interventions in the survey responses}
    \label{fig:avoidance}
    \end{figure}
	For each of these interventions, a respondent chose one of three possible responses: \emph{Never}, \emph{Sometimes}, or \emph{Always}. Figure~\ref{fig:avoidance} gives the distribution of survey responses for the 14 interventions. We observe that washing hands with soap is the most popular intervention, for which more than $82\%$ of the survey participants selected the always response. On the other hand, using surgical mask as an intervention against Influenza was the least popular intervention for which only $10\%$ of the participants selecting the always response. We assume that if a respondent selected \emph{Sometimes} or \emph{Always} for an intervention, they undertake that intervention in their daily lives to avoid getting an influenza infection. Selecting \emph{Never} for an intervention implies that the respondent does not undertake that intervention. This simplifying assumption transforms an individual's choice of interventions into a binary decision problem. 
    \begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/uniquevectors.png}
    \caption{Distribution of influenza avoidance behaviors observed in the survey.}
    \label{fig:avoidancedist}
    \end{figure}
	Furthermore, an individual can undertake a combination of these interventions, for example, one might undertake three interventions: avoid touching eyes (ATE), wash hands with soap (WHS) and get recommended vaccine (GRV), so as to avoid getting an influenza infection. We found that there were $351$ such intervention combinations in the survey responses. From here on, we refer to these interventions as actions and a combination of interventions as behaviors. Therefore, an individual`s choice of actions constitutes their behavior. Figure~\ref{fig:avoidancedist} gives the frequencies of each of the behaviors observed in the survey, with the data plotted on $\log_{10}$ scale. Here, the most likely behavior (marked by 1 on the horizontal axis) corresponds to choosing all interventions and is adopted by 385 survey respondents. The first 10 behaviors are selected by 60\% of the individuals. Additionally, 58\% of the behaviors (i.e., behaviors 145 to 351) have a frequency of 1.
    
	
	\chapter{Epidemic Simulations} \label{ch:epi-simulations}
	Large-scale agent-based epidemic simulators work on social contact networks \cite{Glass2008}, to simulate the spread of social contagions such as epidemics, social memes, news and information through these networks. Each node in a social contact network represents a person and each edge represents a temporal contact (i.e., an interaction) between two nodes. The social contact network is thus a dynamic graph where edges or connections between nodes would change based on the schedule followed by individuals that are represented by the nodes. 
	\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{figures/scn.png}
    \caption{Toy social contact network.}
    \label{fig:scn}
    \end{figure}
	Figure~\ref{fig:scn} shows a toy social contact network with 15 nodes representing 15 people and 15 possible connections (dynamic edges). The blocks represent different locations and the connections may form as the two individuals represented by the nodes in the ``home'' location go about visiting the other 4 locations in the course of their typical day.
	
	In this study we use Episimdemics \cite{barrett2008episimdemics}, which simulates the spread of infectious diseases through the social contact network corresponding to a synthetic population. Synthetic populations are commonly used in large-scale simulations in multiple domains, including influenza epidemics~\cite{EG+04,parikh14cover}, disaster response~\cite{parikh13nps1}, and more. Next, we briefly describe the process of generating the synthetic population for Montgomery County, Virginia.  
    
    \section{Synthetic population}
    The synthetic population of Montgomery County, VA, is available online \footnote{\url{http://ndssl.vbi.vt.edu/synthetic-data/}}. It represents all the residents of Montgomery County and has 77,820 people grouped into 32,827 households. Each synthetic individual is assigned a daily activity schedule, with multiple activities in the day. The total number of activities is 429,590, and these activities are carried out in 26,941 distinct geographic locations. A location can have different sizes and can contain ``sublocations'' (e.g., rooms within buildings), which can accommodate 25 to 50 people. The synthetic population is constructed in a series of steps by integrating data from multiple sources like the American Community Survey (ACS)~\cite{mather2005american}, the National Household Travel Survey (NHTS)~\cite{NHTS11} and HERE (formerly NAVTEQ, for road network data). The process employs algorithms like the iterative proportional fitting (IPF) algorithm~\cite{BBM96} and gravity model~\cite{erlander90gravityModel} to generate a synthetic population which is statistically indistinguishable from the real population. A person-person social contact network can be derived from this synthetic population by assuming that people who are at the same location for an overlapping period of time are in contact with each other. Details of the process can be found in the report by Adiga et al.~\cite{adiga15US}. The resulting social contact network has 77,820 nodes representing people and over 2 million edges representing the contacts between these people in Montgomery County, VA. Episimdemics operates on this person-person social contact network, and simulates agents or synthetic individuals as nodes of the network ~\cite{swarup14challenge}. The spread of contagions through the social contact network is modeled through coupled contagion propagation and contagion progression models.
    
    \section{Contagion propagation and progression models}
    The contagion propagation (inter-host) and contagion progression (intra-host) models used in this work were developed by the National Institutes of Health, Models of Infectious Disease Agent Study (MIDAS) project~\cite{nih09midas}. The inter-host model specifies how an uninfected agent gets exposed to the disease by an infected agent. Such exposures are probabilistic in nature and result from interaction between agents~\cite{barrett2006modeling}. We can use a probability function to model the probability of a susceptible agent $i$ getting infected based on its immediate social contact network neighborhood and disease, and agent- and environment-specific parameters. The probability function is defined as,
    \begin{align}
    p_i = 1 - \exp \Bigg(  \tau \sum_{r \in R} N_r \ln (1-r s_i \rho) \Bigg).
    \label{eqn:1}
    \end{align}
    Here, $p_i$ is the probability of a susceptible agent $i$ getting infected, $\tau$ is the duration of exposure in minutes, which is the time spent by agent $i$ at the same location as $N_r$ (collocated) infectious agents, $R$ is the set of infectivities ($r$s) of each of the $N_r$ infectious agents collocated with the susceptible agent $i$, $s_i$ is the susceptibility of $i$ and $\rho$ is the probability of a single completely susceptible agent getting infected by a single completely infectious agent through one minute of exposure \cite{barrett2007modeling}. This model ensures that the presence of multiple infected agents in the neighborhood of a susceptible agent increases the agent's probability of getting infected. Conversely, absence of infected neighbors makes the probability of getting infected for a susceptible agent equal to zero. 
    \begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{figures/dpm.png}
    \caption{Contagion propagation model.}
    \label{fig:dpm}
    \end{figure}
    
    Figure~\ref{fig:dpm} shows a graphical representation of the inter-host disease propagation model. Here, the green nodes represent susceptible individuals and red nodes represent infectious individuals. Each susceptible node has an associated susceptibility parameter, which is depicted at the center of the green nodes. Similarly, each infectious node has an associated infectivity parameter, depicted at the center of the red nodes. Now, using the disease propagation model defined in equation~\ref{eqn:1}, we can compute the probabilities of infection for each of the susceptible nodes in figure~\ref{fig:dpm}. Since, nodes $j$ and $k$ do not have any infectious neighbors their probability of infection comes out to be $p_j = p_k = 1 - \exp (\tau * 0 ) = 1 - 1 = 0.0$. On the other hand, since the node $i$ has two infectious neighbors, its probability of infection comes out to be non-zero, i.e., $p_i = 1 - \exp (\tau * (\ln (1 - (r_1 s_i \rho)) + \ln (1 - (r_2 s_i \rho))))$. Table~\ref{table:1} shows the specific values of the Influenza propagation model parameters used in this work. 
    \begin{table}[!t]
    \renewcommand{\arraystretch}{1.3}
    \centering
    \caption{Variable values used in the influenza propagation model}
    \begin{tabular}{|l|c|}
    \hline
    \multicolumn{1}{|c|}{\textbf{Variable}} & \textbf{Value}  \\ \hline
    $r$ in Susceptible states & $0.0$ \\ \hline
    $r$ in Exposed state & $0.0$ \\ \hline
    $r$ in Infectious state & $1.0$ \\ \hline
    $r$ in Recovered state & $0.0$ \\ \hline
    $s_i$ in Susceptible states & $[0.574649378, 1.0]$ \\ \hline
    $s_i$ in Exposed state & $0.0$ \\ \hline 
    $s_i$ in Infectious state & $0.0$ \\ \hline
    $s_i$ in Recovered state & $0.0$ \\ \hline
    $\rho$ & $1.0$ \\ \hline
    \end{tabular}
    \label{table:1}
    \end{table}
    
    Upon getting infected the progression of the disease within an agent is modeled using the disease progression or intra-host model. This model is a Probabilistic Timed Transition System (PTTS), which is a finite state machine with probabilistic and timed state transitions~\cite{bisset2009modeling}. The specific PTTS we use in this work models the well-known SEIR compartmental model, typically used for mathematical modeling of infectious diseases. Figure~\ref{fig:disease} shows a schematic of the disease PTTS that we have used in this work for simulating the progression of Influenza within an individual. 
    \begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/disease-fsm.pdf}
    \caption{Within-host disease PTTS}
    \label{fig:disease}
    \end{figure}
    
    Each agent remains in the susceptible (S) state until it comes in contact with one or more infected agents in its social contact network neighborhood. Then we calculate $p_i$ based on the susceptibility of agent $i$ (which in turn depends on its behaviors) and the number of infected agents in the neighborhood ($N_r$). Agent $i$ is then set to be exposed with probability $p_i$. In this case, the probability of getting infected (i.e., $p_i$) increases for the susceptible agent. The value of $p_i$ is used to determine whether or not the disease was transmitted to the susceptible agent using a random draw from the uniform distribution $\mathcal{U}(0,1)$. If the random draw comes out to be less than the value of $p_i$ for an agent, it is considered as a successful transmission. 
    
    In this case the agent's disease PTTS transitions to the exposed (E) state from the Susceptible (S) state. An agent remains in the exposed (E) state for a period of one to two days after which it transitions into the infected (I) state. The exact duration (in hours) for which an agent remains in the exposed state before transitioning to infected state is once again determined by a random draw from the uniform distribution $\mathcal{U}(24,48)$. However, a transition to the infected state is guaranteed to happen in $48$ hours of getting infected. Once an agent transitions to the infected state, it remains infectious for a period of two to six days, after which it transitions to the recovered (R) state. The duration (in days) for which an agent stays in the infected state is determined using the distribution: ($3$ days$/4$ days$/5$ days$/6$ days), ($0.3/0.4/0.2/0.1$) as shown in the histogram presented in Figure~\ref{fig:disease}. Agents in the infectious state can spread the infection to other susceptible agents, which come in contact with them through the social contact network as evident by the infectious agent's infectivity of $(1.0)$. An agent in the recovered state is no longer contagious and cannot get new infections.
    
    \section{Information Contagion}
    The intra-host and inter-host models can also be used to simulate the propagation of other contagions in the social contact network. One such contagion is that of information about the disease outbreak, which can be used to trigger decision making about the disease avoidance behavior in the agents. Figure~\ref{fig:information} shows the PTTS which models the information contagion about the influenza outbreak. 
    \begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{figures/information-fsm.pdf}
    \caption{Within-host information PTTS}
    \label{fig:information}
    \end{figure}
    This within-host information PTTS functions similarly to the disease PTTS, but has only two states (i.e., uninformed and informed). Initially, all agents are in the ``uninformed'' state, but once an agent gets infected by the influenza contagion, its information state changes to ``informed''. Agents in the contact network neighborhood of an infected agent get informed about the outbreak faster than they get infected. This is achieved by having an information contagion susceptibility two times the susceptibility to the disease contagion. This results in the information about the disease outbreak spreading faster than the disease itself. The information contagion model reflects the role of peer influence in an individual's decision-making. Table \ref{table:2} lists the specific values of the variables that were used for the information contagion in our simulations.
    \begin{table}[!t]
    \renewcommand{\arraystretch}{1.2}
    \caption{Variable values used in the info. propagation model}
    \centering
    \begin{tabular}{|l|c|}
    \hline
    \multicolumn{1}{|c|}{\textbf{Variable}} & \textbf{Value}  \\ \hline
    $r$ in Uninformed state & $0.0$ \\ \hline
    $r$ in Informed state & $1.0$ \\ \hline
    $s_i$ in Uninformed state & $2.0$ \\ \hline
    $s_i$ in Informed state & $0.0$ \\ \hline 
    $\rho$ & $1.0$ \\ \hline
    \end{tabular}
    \label{table:2}
    \end{table}
    Upon receiving information about the outbreak, an agent can decide to undertake one or more actions so as to avoid getting the disease. In the context of influenza, an agent can undertake any of the $351$ combinations of the $14$ actions that were discussed in Section 3. 
    
    \section{Interventions}
    
    Until now we have looked at processes that are sufficient to simulate the spread of contagions like disease and diffusion of information in large synthetic populations. Here, we describe how individual interventions and their combinations are implemented in the simulation. We assume that adopting an intervention can affect an individual in multiple ways. 
    
    First, adopting hygienic practices like, washing hands with soap and using hand sanitizers in the real world reduce an individuals susceptibility to the disease. Therefore, when an agent decides to adopt a hygienic practice in an epidemic simulation, we simply reduce its susceptibility parameter. Additionally, adopting more interventions would make an individual even more protected in the real world. This implies that the reduction in susceptibilities always add up, i.e., for an agent adopting more interventions result in larger reduction in its susceptibility. 
    
    Second, certain interventions lead to a change in an individual`s schedule, which can affect the structure of the social contact network of the population under consideration. For example, if an individual decides to completely stops visiting any crowded place upon receiving information about a disease outbreak, the likelihood that it will get an infection from any of the said crowded places goes to zero. Such interventions are broadly classified as social distancing and aim to make the nodes in a social contact network less connected, so as to control disease spread. 
    
    Third, vaccines are generally thought of as making individuals immune to the particular disease. Therefore, in an epidemic simulation any agent deciding to adopt the vaccine intervention would become immune to the disease. This translates to changing the state of the within-host PTTS to the ``Recovered'' state. While this is rather straightforward to implement, vaccine efficacy can vary with not just with the disease, but with a myriad of factors. For example, different strains of the circulating pathogen, host factors like age, prior exposure to the pathogen, time since vaccination and vaccine characteristics like live or inactivated, mode of delivery. This is more often than not true in the case of Influenza. Hence, for the sake of simplicity we can think of vaccination as just another hygienic practice intervention, that reduces the susceptibility to the disease, instead of making the agent completely immune to the disease.
    
    Finally, an individual can adopt a combination of all of any of these interventions, which constitutes its behavior. Therefore, adopting a particular intervention combination can reduce the susceptibility of an agent to the disease as well as affect its contact neighborhood (which impacts the overall social contact network of the synthetic population being simulated). It is important to note that measuring or estimating the exact reduction in susceptibility caused by an intervention is difficult, but we can rely on domain-experts for this information. In this work, we assume that if an intervention is easy to take then a lot of people will adopt it, but it will also have a smaller effect on the susceptibility to the disease. Hence, the reduction in susceptibility due to an intervention is assumed to be an inverse function of the number of survey participants who responded as undertaking that intervention. 
    
    Therefore, upon receiving information about the Influenza outbreak, a susceptible agent decides to undertake an intervention combination, (i.e., a behavior) using the MDP decision-making model. In order to account for the $351$ possible behaviors that can be decided upon, we modify the within-host PTTS shown in figure~\ref{fig:disease} to the one shown in figure~\ref{fig:disease-behavs}.
    
    \begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/disease-fsm-behavs.pdf}
    \caption{Modified within-host disease PTTS}
    \label{fig:disease-behavs}
    \end{figure}
    
    Once an agent has decided on a behavior their disease PTTS is transitioned to one of the susceptible states (shown in purple) in figure~\ref{fig:disease-behavs}. In other words, if an agent decides to adopt behavior $b$ the PTTS corresponding to that agent is transitioned to the Susceptible\_$b$ state. Each of these $351$ susceptible states implies a lower susceptibility towards influenza for the agent than the original Susceptible (S) state. Additionally, if the behavior contains a social distancing intervention like avoiding crowded places or contact with people who are sick, the schedule of the behaving agent is changed to reflect that intervention. 
    
    We note that the assumed inverse relationship between ease of undertaking an action and the reduction in susceptibility associated with it may or may not hold in the real world. This assumption and the simplified disease and information models used in this study are not central to the behavior calibration methodology and merely serve the purpose of demonstrating the behavior calibration approach, which is the main contribution of this work. Given the availability of quantitative data linking actions with reduction in susceptibility, one can easily eschew this assumption, without affecting the overall behavior calibration approach. Additionally, the disease and information models can be substituted with more complex variants for modeling any infectious disease as well as peer influence. In the next chapter, we define the agent decision-making model central to this work.

    \chapter{Agent decision making model}\label{ch:decision-model}
    We define the Markov decision process (MDP) driving agent decision making as a $4$-tuple $\big<\mathcal{S,B,P,R}\big>$. The state space $\mathcal{S}$ consists of all the possible health and information states for an agent, which are reflected in the states of the within-host disease and information PTTSs shown in figures~\ref{fig:disease-behavs}~and~\ref{fig:information}. Therefore, if the sets of possible health and information states are $S_H$ and $S_I$ respectively, the total number of possible states for an agent are $|S_H| X |S_I|$. In this work, we have kept $S_H = 355$ (i.e., the four S, E, I and R states and the 351 Susceptible states) and $S_I = 2$, resulting in a total of $710$ possible states for an agent. The behavior space $\mathcal{B}$ consists of the $351$ behaviors that an agent can adopt, which were observed in the outbreak survey. The transition model $\mathcal{P}$ determines the transitions in the state space $\mathcal{S}$, given a behavior $b \in \mathcal{B}$. In other words, $\mathcal{P}_b(s,s') = P(s_{t+1} = s' | s_t = s, b_t = b)$ defines the probability that for an agent adopting behavior $b$ in state $s$ at time $t$ will lead to state $s'$ at time $t+1$. In the case of epidemic simulations, these transition probabilities are dependent on the disease and information diffusion happening in the simulation which are complex phenomena. Hence, in this work the transition function $\mathcal{P}$ of the MDP is intensively specified by the simulation model and cannot be computed extensively. 
    
    Lastly, the reward function $\mathcal{R}_b(s, s')$ in an MDP determines the reward received by an agent upon transitioning form a state $s$ to state $s'$, due to behavior $b$, here, $s, s' \in \mathcal{S}$ and $b \in \mathcal{B}$. In the context of this work, we associate not getting infected i.e., remaining in one of the susceptible states with a positive reward for an individual and adopting an avoidance behavior with a negative reward (or cost). Thus, on a particular day in the simulation, if an agent remains in one of the susceptible states they receive a positive reward of $+1$. Additionally, if the agent has adopted any of the avoidance behaviors we subtract the cost associated with that behavior from the net reward collected by the agent. The key idea here is that, an agent can select a behavior, which will reduce its immediate reward, but will also lead to a lower susceptibility to the disease. This would increase its odds of remaining in one of the susceptible states, 
    thereby increasing its likelihood of collecting future rewards. Since, in our case the immediate reward is only dependent on the current state and the selected behavior, we can state the immediate reward associated with behaviors $b$ and state $s$ as $\mathcal{R}_b(s)$.

    The behavioral decision for a susceptible and informed agent is to select an optimal behavior such that its accumulated reward over the simulation duration is maximized. On a particular day in the simulation, this behavioral decision depends on the agent's probability of getting exposed and the cost associated with the $351$ behaviors. Taking these aspects into account, we define a value function $V_d(b)$ associated with a behavior $b$ on a day $d$ as follows,
    \begin{align*}
    V_d(b) &= \sum_{i=d}^D \bigg\{ \mathbb{E} [\mathcal{R}_b(s_i)] \bigg\}  \\
        &= \sum_{i=d}^D \bigg\{ (1 - cost_b) * P(s_i \in \mathcal{S}_{Susceptible}) \bigg\} 
    \end{align*}
    Here, $D$ is the total number of days for which the epidemic is being simulated, $\mathcal{R}_b(s_i)$ is the immediate reward associated with the state $s_i \in \mathcal{S}$ and behavior $b \in \mathcal{B}$. Therefore, the value function associated with behavior $b$ on day $d$ is the sum of all expected rewards from the current day $d$ until the end of the epidemic simulation. Assuming $\mathcal{S}_{Susceptible} \subset \mathcal{S}$ is the set of all states in the MDP, in which the agent`s health state corresponds to one of the susceptible states defined in the disease PTTS. The expected daily reward collected by an agent, who has adopted behavior $b$ and is in the state $s \in \mathcal{S}_{Susceptible}$ of the MDP, can be given by the $+1$ reward for being susceptible (i.e., not being exposed to the disease) minus $cost_b$, which is the cost associated with the behavior $b$. Since, this reward is only valid if the state $s \in \mathcal{S}_{Susceptible}$, we also need factor in the probability that the agent`s state $s_i$ on day $i$ belongs to the $\mathcal{S}_{Susceptible}$ set. We do this by multiplying the expected reward with the $P(s_i \in \mathcal{S}_{Susceptible})$. In addition, as the reward for being in a state $s' \notin \mathcal{S}_{Susceptible}$ is zero, we do not consider these rewards in our formulation of the value function. 
    
    As the membership of a state $s$ in the set $\mathcal{S}_{Susceptible}$ is only determined by the disease PTTS, we can further simplify the value function as follows,
    \begin{align}
    V_d(b) &= \sum_{i=d}^D \bigg\{ (1-cost_b) * (1 - P_i(S \rightarrow E|b)) \bigg\} 
    \label{eqn:valfn}
    \end{align}
    Here, $P_i(S \rightarrow E|b)$ is the probability of any agent in the population transitioning from one of the susceptible states ($S$) to the exposed state ($E$) on the $i^{th}$ day of the simulation, given that the agent undertakes the behavior $b$. The probability of not transitioning to the exposed state on day $i$ can hence be written as, $1 - P_i(S \rightarrow E|b)$). Since the goal of every agent is to maximize the collected reward, the optimal behavior choice for every susceptible and informed agent on day $d$ will be the one that maximizes the value function defined in the equation \ref{eqn:valfn}. 
    
    As we have discussed earlier that the transition function $\mathcal{P}$ of the MDP cannot be computed extensively, we can only estimate the probability term $P_i(S \rightarrow E|b)$ for computing the value function. We estimate $P_i(S \rightarrow E|b)$ for an agent on day $i$ of the epidemic simulation, based on the extent to which the disease has spread through the population as shown below,
    \begin{align}
    P_i(S \rightarrow E|b) &= f_i  \prod_{t=0}^{(i-1)} (1 - f_t)
    \label{eqn:2}
    \end{align}
    Here, $f_i$ is the fraction of agents in the population that have transitioned to the exposed state by the day $i$ (exposed agents) given that the entire agent population has adopted the avoidance behavior $b$. Since, $f_i$ is an agents best estimate of the probability of being exposed to the disease on day $i$, we can interpret \ref{eqn:2} as the probability that the agent did not get exposed to the disease before day $i$ (i.e., the agent remained susceptible from from day $0$ till day $i-1$) and got exposed on the $i^{th}$ day. Since an agent does not have access to the full state of the simulated population, we use a simple differential equation model of the SEIR process \cite{hethcote1976qualitative} to estimate the fractions of exposed agents in the population on subsequent epidemic simulation days, for a particular behavior $b$. The following differential equations describe the ODE model,
    \begin{align*} 
    		\frac{dS}{dt} &= \mu - (\beta I + \mu) S, \\
    		\frac{dE}{dt} &= \beta S I - (\mu + \sigma) E, \\
    		\frac{dI}{dt} &= \sigma E - (\mu + \gamma) I, \\
    		\frac{dR}{dt} &= \gamma I - \mu R.
    \end{align*}
    \begin{table}[!t]
    \renewcommand{\arraystretch}{1.2}
    \caption{Variable values used in the ODE model}
    \centering
    \begin{tabular}{|l|c|}
    \hline
    \multicolumn{1}{|c|}{\textbf{Variable}} & \textbf{Value}  \\ \hline
    ODE simulation duration & $100$ days\\ \hline
    $\mu$ & $0.0$ \\ \hline
    $\beta$ & $[0.3,0.6]$ \\ \hline
    $\gamma$ & $0.125$ \\ \hline
    $\sigma$ & $0.5$ \\ \hline
    Initial proportion of exposed agents & $0.0001$ \\ \hline 
    Initial proportion of infectious agents & $0.0001$ \\ \hline
    Initial proportion of susceptible agents & $0.9998$ \\ \hline
    Initial proportion of recovered agents & $0.0$ \\ \hline
    \end{tabular}
    \label{table:ode}
    \end{table}
    Here, $S,E,I$ and $R$ represent the number of susceptible, exposed, infectious and recovered agents in a population. $\mu$ and $\beta$ represent the natural mortality and transmission rates respectively. $\gamma$ and $\sigma$ represent the recovery and infection rate respectively. For the purpose of this study, the values of variables used in the ODE model are listed in Table~\ref{table:ode}. We assume the natural mortality rate to be zero and the values of other variables are taken from a standard ODE based SEIR model~\cite{keeling2008modeling}. Also, similar to the disease PTTS, repeated exposure is not modeled in this work because once an agent gets infected and recovers, they cannot be infected again by the same strain of influenza virus. 
    
    The ODE model generates epidemic curves or ``epicurves'', which represent the fraction of exposed individuals in the population over time. We can use these fractions to estimate $P_i(S \rightarrow E|b)$ as per equation~\ref{eqn:2}. We assume that adopting one of the $351$ behaviors would lead to a change in the transmission rate ($\beta$), while the recovery and infection rates ($\gamma$ and $\sigma$) would remain unchanged. This assumption leads to a range of $\beta$ values in the interval of 0.3 to 0.6. This is the reason why we have specified $\beta$ as a range in table~\ref{table:ode}, instead of a single value. Each of these $\beta$ values corresponds to one of the 351 behaviors and results in a different epicurve. Figure \ref{fig:epicurves} shows 21 of the 351 Epicurves generated by the ODE model for the avoidance behaviors discovered in the outbreak survey.
    \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/epicurves.png}
    \caption{Epicurves generated by the ODE model for 21 of the 351 behaviors}
    \label{fig:epicurves}
    \end{figure}
    
    On each day of the simulation, each agent has to choose a behavior based on its estimate of its probability of getting infected. Since, we can now estimate $P_i(S \rightarrow E|b)$, we can use equation~\ref{eqn:valfn} to compute the values associated with the $351$ behaviors and the agent can select the optimal behavior $b$ for any day $d$ in the simulation such that,
    \begin{align}
        max_{b} V_d(b)
    	\label{eqn:optb}
    \end{align}
    During each simulation day any susceptible agent who has received information about the outbreak would choose to undertake the optimal behavior. The MDP, the epicurves generated by the ODE model and the behavior selection process together constitute the agent decision making model or behavior model.  
    
    Note that, the costs associated with the behaviors are still unknown and need to be determined for the model behavior model to operate. The survey described in chapter~\ref{ch:survey} gives information about the behaviors that people do, but does not provide any clues about the perceived cost of these behaviors. It is important to understand that these costs do not refer to the actual dollar costs that might be associated with a set of interventions, rather its an implicit behavior model parameter that discounts the immediate rewards generated by the reward function of the MDP.
    As an example, people may not prefer to use surgical masks, even though they provide the best protection against infection, because of perceptions of a lack of social acceptability to their daily use. We posit that these costs are a parameter of the behavior model which can be tuned such that the distribution of behaviors adopted by agents in the epidemic simulation would match the distribution of behaviors observed in the real world. To determine these implicit costs, we calibrate the model by treating it as an inverse reinforcement learning problem where we use the epidemic simulator in a loop with an optimizer to estimate the optimal costs. This is described in the next section.
    
    \section{Behavior model calibration}
    We consider the distribution of behaviors selected by participants of the outbreak survey as our real world observations. We calibrate the $cost_b$ parameters associated with behaviors of the behavior model so as to minimize the mean squared error (MSE) between the simulation and survey distributions of the $351$ observed behaviors. Thus, the objective of behavior model calibration is to compute an optimal cost, $cost_b^*$, associated with behavior $b$, $\forall b \in \mathcal{B}$. This can be viewed as an inverse reinforcement learning problem~\cite{ng2000algorithms} where given the States, Actions and Transitions (i.e., \big<$\mathcal{S,A,P}$\big>) of an MDP, along with some estimate of an optimal policy $\pi^*$, an optimal reward function $\mathcal{R}$ is estimated. We specify the costs associated with the $351$ behaviors in a vector $C$, such that each element $c_i \in C$ corresponds to $cost_i$ $\forall 0 \le i \le 350$. The objective function $J(C)$ is defined as follows,
    \begin{align}
        J(C) &= \frac{1}{2 * |C|} \sum_{b \in B}\bigg[ N_{C_b} - N_{b} \bigg]^2
    		\label{eqn:objfn}
    \end{align}
    \begin{align}
    		C^* &= \argmin_C J(C) 
    		\label{eqn:optc}
    \end{align}
    Here, $N_{C_b}$ is the proportion of agents which decide to follow the behavior $b$ in the simulation, given the cost vector $C$. $N_{b}$ is the proportion of survey respondents that selected behavior $b$. In equation (\ref{eqn:optc}), $C^*$ is the optimal cost vector, which minimizes the objective function $J(C)$, thereby minimizing the difference between the distribution of behaviors produced by the agent decision model used in the simulation and those observed in the survey data. Note that $N_{C_b}$ is derived from the simulator and it depends on the simulation inputs like, the social contact network, the disease and information characteristics, as well as the behavior model inputs like the cost vector $C$. We can think of the simulator as a function $\mathscr{S}$ which transforms the various simulation and behavioral model inputs to proportions of agents following the different behaviors, i.e., $N_{C_b}$. In other words, the function $\mathscr{S}(\cdot, C)$ represents the simulator output corresponding to $N_{C_b}$ (i.e., $\mathscr{S}(\cdot, C) = N_{C_b}$) and we can re-write equation~\ref{eqn:objfn} as follows,
    \begin{align}
        J(C) &= \frac{1}{2 * |C|} \sum_{b \in B}\bigg[ \mathscr{S}(\cdot, C) - N_{b} \bigg]^2
    	\label{eqn:objfn2}
    \end{align}
    If we had an extensive mathematical definition of the simulator $\mathscr{S}$, we can differentiate $J(C)$ with respect to $C$ and use any of the popular gradient based optimization techniques to find the optimal cost vector $C^*$ which minimizes $J(C)$. We can say that the behavior model is calibrated with the survey, once the optimization converges. However, as we have discussed earlier an extensive mathematical definition of $\mathscr{S}$ does not exist, hence we can only use gradient-free optimization methods to estimate the optimal cost vector $C^*$. We experiment with three such gradient-free optimization methods, viz. Numerical Gradient Descent (NGD), Cross Entropy (CE) method and Smoothed-Cross Entropy (SCE) method, which we describe next. 
    \begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/ngd.pdf}
    \caption{Flow chart of numerical gradient descent for behavior model calibration}
    \label{fig:ngd}
    \end{figure}
    \begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/cem.pdf}
    \caption{Flow chart of CE method for behavior model calibration}
    \label{fig:cem}
    \end{figure}
    \subsection{NGD for behavior model calibration} 
    In this approach, we begin with a random cost vector $\hat{C}$ and generate $K-1$ cost perturbations uniformly around $\hat{C}$. This can be achieved by sampling $K-1$ points uniformly from the surface of an $n-sphere$ centered at $\hat{C}$, where $n = 351$ is the dimensionality of $\hat{C}$. The $K$ cost vectors (i.e. $\hat{C}$ along with $K-1$ perturbations) form the set of candidate optimal cost vectors which are used to parametrize the agent decision making model in $K$ Episimdemics influenza simulations. In each of the $K$ simulations, agents employ the corresponding cost vector along with the ODE SEIR model to decide on behaviors as influenza and information propagate through the social contact network. Each of the $K$ simulations result in a distribution of behaviors. Thus, we can compute the objective function defined in equation (\ref{eqn:objfn}) for each of the $K$ cost vectors and compute the optimal cost vector $C^*$ out of the $K$ cost vectors which has the minimum value of $J(C)$. We then generate $K-1$ new cost vectors around $C^*$ and repeat this process over $n$ iterations to get successively better optimal cost vectors, or until the value of the objective function $J(C)$ falls below a particular threshold. Figure~\ref{fig:ngd} shows the flow chart of the NGD algorithm applied to behavior model calibration.
    \subsection{CE method for behavior model calibration}
    An issue with NGD is that of slow convergence. One way to achieve faster convergence is to use a fast Monte Carlo-based combinatorial optimization algorithm like the Cross Entropy (CE) method~\cite{kroese2013cross,stulp2012path}. The CE method operates by generating a random data sample using a particular mechanism (e.g., sampling from a Gaussian distribution), followed by updating the parameters of the mechanism (e.g., updating the mean and variance of the Gaussian distribution) to produce a ``better'' sample in the next iteration. In the case of using CE method for behavior model calibration, once again we begin with a random cost vector $\hat{C}$ and generate $K-1$ perturbations uniformly around $\hat{C}$ from the surface of an $n-sphere$ centered at $\hat{C}$. The $K$ perturbations are used to parametrize the agent decision making model in $K$ Episimdemics influenza simulations. Similar to NGD, we then compute the value of objective function $J(C)$ for each of the K perturbations. However, instead of selecting one perturbation with the minimum value of $J(C)$, we select $P$ perturbations that have the least values for the objective function $J(C)$ out of the $K$ perturbations. Next, we compute the mean $m$ and covariance matrix $S$ for these top $P$ perturbations and use the multi-variate Gaussian distribution $\mathcal{N}(m,S)$ to once again generate $K$ perturbations for use in the next iteration. We continue this process for $n$ iterations before reporting the results. Figure~\ref{fig:cem} shows the flow chart for the CE method applied to behavior model calibration.
    
    \subsection{Smoothed-CE method for behavior model calibration}
    In our experiments we observed that the covariance matrix $S$ computed by the CE method quickly converged to zeros at an early stage of the optimization. This is analogous to the algorithm getting stuck in a local minimum. In order to prevent this behavior of the CE method, we use a smoothing parameter $\alpha$ to update the mean $m_t$ and covariance matrix $S_t$ on the $t^{th}$ iteration~\cite{mannor2003cross}.
    \begin{align}
        m_t &= \alpha  \hat{m} + (1-\alpha)  m_{t-1}
    		\label{eqn:smean}
    \end{align}
    \begin{align}
    		S_t &= \alpha  \hat{S} + (1-\alpha)  S_{t-1}
    		\label{eqn:scovmat}
    \end{align}
    
    Here, $\hat{m}$ is the mean and $\hat{S}$ the covariance matrix of the top $P$ perturbations computed for iteration $t$, $m_{t-1}$, $S_{t-1}$ is the mean and covariance matrix computed for the last iteration (i.e. $t-1$) and $\alpha$ is the smoothing parameter such that $0 < \alpha < 1$. 
    
    \subsection{Using Quantal Best Response for agent decisions}
    Upon closer analysis of our calibration results from the optimization approaches discussed until now, we found that we were able to match the distribution of the $14$ behavioral interventions observed in the survey with those observed in the simulation to a great extent. Although the distribution of the $351$ behaviors did not seem to match very well between the survey and the epidemic simulation. To address this problem we, modified a few aspects of the Smoothed-CE method, which resulted in much better calibration of the behavior distributions.
    
    First, we replaced the mean squared error (MSE) objective function with a sum of squared error (SSE) objective function. This modification was aimed at making the loss more sensitive to large differences between the behavior proportions observed in the simulation and the outbreak survey. Since, the MSE essentially averages all the squared errors, it starts to reduce as soon as some of the errors drop to zero. The reduction in MSE is also affected by the number of behaviors. In other words as the number of behaviors grows, the MSE value reduces substantially because of the $2 * |C|$ term in the denominator. On the other hand, as the SSE does not average the squared error values, it is more sensitive to large errors and is also independent of the number of behaviors. The new objective function is as follows,
    \begin{align}
        J(C) &= \sum_{b \in B}\bigg[ N_{C_b} - N_{b} \bigg]^2
    	\label{eqn:objfn3}
    \end{align}
    
    Second, past work in the cognitive sciences and behavioral game theory suggests that instead of selecting the behavior with the maximum value (or utility), agents respond stochastically to their incentives. This means that agents select high value behaviors with high probability and low value behaviors with low probability~\cite{wright2014level}. This model of behavioral response is called the Quantal Best Response (QBR), and given a value function $V_d$ to quantify the utility associated with a behavior $b$ on a day $d$, an agent`s behavior choice is determined by the strategy $\mathbb{S}$, which is defined as follows,
    \begin{align}
        \mathbb{S}(b) &= \frac{\exp (\lambda * V_d(b)) }{ \sum\limits_{b' \in B} \big[ \exp(\lambda * V_d(b')) \big]}
    	\label{eqn:qbr}
    \end{align}
    Here, $\lambda$ refers to the precision or the agent`s sensitivity to differences in the values associated with different behaviors. When $\lambda = 0$, the strategy $\mathbb{S}$ would always be equal to $1$, resulting in the agent`s behavior choice to be uniformly distributed over all possible behaviors in $B$. Conversely, as $\lambda \rightarrow \infty$, the strategy $\mathbb{S}$ would converges to the best behavior, instead of being a distribution over all the behaviors. This leads to the agent`s behavior choice always being the behavior $b$, that maximizes $V_d(b)$, similar to our earlier approach (i.e., equation~\ref{eqn:optb}). In this work, we use $\lambda = 1$, so as to allow an agent`s behavior choice to be stochastic, while being aligned with the quantal response principle. This means that behaviors having a high value would be selected with a higher probability and those with a low value would be selected with a low probability.
    
    Therefore, the QBR method gives us a probability distribution over the behavior space, from which we can sample a single behavior using Inverse Transform Sampling~\cite{wiki:its}. The sampled behavior is then adopted by the agent in the epidemic simulation. Note that the rest of the optimization process remains unchanged, and in this work we only apply the QBR method alongside the Smoothed-CE optimization method. In the next chapter, we present the calibration results obtained using the methods we have discussed so far. explain results in more detail
    
	\chapter{Results} \label{ch:results}
	\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/marginals.png}
    \caption{Distribution of influenza avoidance action choices observed in the survey, those generated by an uncalibrated agent decision model and those generated by the three calibration approaches}
    \label{fig:marginals}
    \end{figure}
    
    \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/meanerrors.png}
    \caption{Mean error between the avoidance action distribution observed in the survey and those generated by the three calibration approaches}
    \label{fig:mean-errors}
    \vspace{-0.1in}
    \end{figure}
    
    In order to compare the calibration results obtained using the different calibration approaches, we initialized each of them with a common $\hat{C}$ vector, with each element in $\hat{C}$ being equal to a constant $c$ (we kept $c=0.5$ in our experiments). We initialized the NGD algorithm with $K=15$ and executed it for $N=2000$ iterations, which resulted in a $J(C)$ value of $0.0001651$. The calibration resulted in a mean error of $0.009268$ for the action choice distribution as shown in Figure~\ref{fig:mean-errors}. In order to obtain faster optimization, we experimented with the CE method, initializing it with $K=30$, $P=15$ and executed it for $N=100$ iterations. This resulted in a $J(C)$ value of $0.00020380$ and a mean error of $0.013574$ for the action choice distributions. Although the final objective function value and the mean error obtained using CE method were worse than those obtained using NGD, the CE method substantially reduced the number of iterations (from $2000$ to $100$), which amounts to a 20 times speedup, since each iteration takes the same amount of time in both the cases. 
    
    We found that the covariance matrix $S$ computed in the CE method converged to zeros on the $30^{th}$ iteration, which stopped the optimization process at an early stage. To address this problem we experimented with the Smoothed-CE (SCE) method, initialized with a smoothing factor $\alpha = 0.5$ and executed it for $N=100$ iterations. This time the calibration process resulted in a $J(C)$ value of $0.00016363$ and a mean error of $0.008447$, which are an improvement over the CE method results and are much closer to the results obtained using NGD. Figure~\ref{fig:marginals} compares the distribution of the intervention choices observed in the survey responses with those generated by an uncalibrated agent decision model and those generated after calibration using NGD, CE method and SCE method.
    
    \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/qbr-marginals.png}
    \caption{Distribution of influenza avoidance action choices observed in the survey, those generated by an uncalibrated agent decision model and those generated by the SCE calibration approach with SSE and QBR modifications.}
    \label{fig:qbr-marginals}
    \end{figure}
    \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/qbr-joints.png}
    \caption{Distribution of behaviors observed in the survey and those generated by a agent decision model calibrated using SCE calibration approach with SSE and QBR modifications.}
    \label{fig:qbr-joints}
    \end{figure}
    
    Lastly, we executed the Smoothed-CE method with the SSE loss and QBR modifications, and a smoothing factor $\alpha = 0.5$ for $N=43$ iterations which resulted in a SSE of $0.00577607$. The intervention and behavior calibration results obtained in this experiment are shown in figures~\ref{fig:qbr-marginals} and \ref{fig:qbr-joints}. Out of all the calibration approaches discussed so fat, the modified-SCE method resulted in the best calibration in both intervention and behavior spaces.
    %\section{Discussion} \label{ch:discussion}
	
	\chapter{Conclusions and Future Work} \label{ch:conclusions}
	In this work, we have shown how to use survey data to calibrate an agent decision making model for a large-scale flu epidemic simulation. The technique is not specific to infectious diseases, so it applies to surveys and simulations in general, though it requires domain-specific decision-making model for each agent akin to the SEIR model used here. The objective of this work was to simulate populations of behaving agents which match the behaving individuals in real populations and exhaustive parameter sweeps for the optimization techniques used in the calibration might improve the results reported here. Additionally, other gradient free optimization techniques like Nelder-Mead Simplex or CMA-ES might lead to different amounts of calibration and performance. In this work, we compared three optimization techniques, although experimentation with other techniques may lead to better or worse results. However, all of these aspects are independent of the basic behavior model calibration approach discussed in this work. 

    While we could construct regression models to predict the probability of an agent adopting a particular behavior using the survey, this does not give us a model of agent decision-making. Our approach develops a model of agent decision-making, which can be interpreted, inspected and compared with other models in the literature. We have developed a very general and practical representation of behaviors for simulations. The behaviors, like options~\cite{sutton99options}, are higher level descriptions that have initiation and termination conditions, and a policy which can alter the actions (in the form of the activity schedule) and the states (in the form of the FSMs) of each agent. This general representation can be adapted to most social simulation scenarios. Of course, there are scenarios where FSMs will not be powerful enough to represent the agent's state, but in that case the behavior model will just have to specify how to work with the more complex representation of state. 
    
    There are many opportunities for extending this work. In general, the scientific process of gathering data through a survey and then developing a model with it proceeds in an abductive loop in the sense of Peirce~\cite{peirce57abduction}. Thus one of the most useful purposes of such simulations is in the ``context of discovery'', i.e., to generate new hypotheses. By integrating behavior models, we can now generate detailed forecasts of behavior adoption, which can then be confirmed (or disconfirmed) through new surveys. The goal is to bring rapidity and rigor into the study of human behavior in context. This need to be done by making the behavior modeling process as data driven as possible and then using the models to drive further hypothesis generation and data collection. 
    
    In general, human behavior, disease dynamics, and interventions co-evolve. So there is not necessarily a static model of human behavior that can be inferred once and used thereafter. The feedback between these three facets of the system needs to be accounted for. This will require modeling how behaviors change over time and under different circumstances. For example, a challenge would be to be able to predict the level of worry that was observed over Ebola in the US even though the number of actual cases was very small. This requires, as a first step, a more careful modeling of the information contagion process, and extending it to include emotion or fear contagion as well (e.g., see~\cite{epstein08coupled}).
	
	% This is the standard bibtex file. Do not include the .bib extension in <bib_file_name>.
	% Uncomment the following lines to include your bibliography 
	%\bibliography{<bib_file_name>}
	%\bibliographystyle{plainnat}   

% 	% This formats the chapter name to appendix to properly define the headers
% 	\appendix

% 	% Add your appendices here.  You must leave the appendices enclosed in the appendices 
% 	% environment in order for the table of contents to be correct.
% 	\begin{appendices}
% 		\chapter{First Appendix} \label{app:appendix_one}
% 			\section{Section one} \label{ase:app_one_sect_1}
% 				\lipsum[1-3]
% 			\section{Section two} \label{ase:app_one_sect_2}
% 				\lipsum[1-3]
% 		\chapter{Second Appendix} \label{app:appendix_two}
% 			\lipsum[2]
% 	\end{appendices}
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}
\end{document}


%****************************************************************************
% Below are some general suggestions for writing you dissertation
%
% 1. Label everything with a meaningful prefix so that you
%    can refer back to sections, tables, figures, equations, etc.
%    Usage \label{<prefix>:<label_name>} where some suggested
%    prefixes are:
%			ch   : Chapter
%     se   : Section
%     ss   : Subsection
%     sss  : Sub-subsection
%			app  : Appendix
%     ase  : Appendix section
%     tab  : Tables
%     fig  : Figures
%     sfig : Sub-figures
%     eq   : Equations
%
% 2. The VTthesis class provides for natbib citations.  You should 
%    in one or more *.bib bibtex files and save them in your working 
%    directory. Suppose you have two bib files: some_refs.bib and 
%    other_refs.bib.  Then your bibliography line to include them
%    will be:
%      \bibliography{some_refs,other_refs}
%    where multiple files are separated by commas.  In the body of 
%    your work you can cite your references using natbib citations.
%    Examples:
%      Citation                     Output
%      -------------------------------------------------------
%      \cite{doe_title_2016}        [18]
%      \citet{doe_title_2016}       Doe et al. [18]
%      \citet*{doe_title_2016}      Doe, Jones, and Smith [18]
%
%    For a complete list of options see
%      https://www.ctan.org/pkg/natbib?lang=en
%
% 3. Here is a sample table.  Notice that caption is centered at the top. Also
%    notice that we use booktabs formatting.  You should not use vertical lines
%    in your tables.
% 
%				\begin{table}[htb]
%					\centering
%					\caption{Approximate computation times in hh:mm:ss for full order versus reduced order models.}
%					\begin{tabular}{ccc}
%						\toprule
%						& \multicolumn{2}{c}{Computation Time}\\
%						\cmidrule(r){2-3}
%						$\overline{U}_{in}$ m/s & Full Model & ROM \\
%						\midrule
%						0.90 & 2:00:00 & 2:08:00\\
%						0.88 & 2:00:00 & 0:00:03\\
%						0.92 & 2:00:00 & 0:00:03\\
%						\midrule
%						Total & 6:00:00 & 2:08:06\\
%						\bottomrule
%					\end{tabular}
%					\label{tab:time_rom}
%				\end{table}
% 
% 4. Below are some sample figures.  Notice the caption is centered below the
%    figure.
%    a. Single centered figure:
%					\begin{figure}[htb]
%						\centering
%						\includegraphics[scale=0.5]{my_figure.eps}
%						\caption{Average outlet velocity magnitude given an average input velocity magnitude of 0.88 m/s.} 
%						\label{fig:output_rom}
%					\end{figure}
%    b. Two by two grid of figures with subcaptions
%					\begin{figure}[htb]
%						\centering
%						\begin{subfigure}[h]{0.45\textwidth}
%							\centering
%							\includegraphics[scale=0.4]{figure_1_1.eps}
%							\caption{Subcpation number one}
%							\label{sfig:first_subfig}
%						\end{subfigure}
%						\begin{subfigure}[h]{0.45\textwidth}
%							\centering
%							\includegraphics[scale=0.4]{figure_1_2.png}
%							\caption{Subcpation number two}
%							\label{sfig:second_subfig}
%						\end{subfigure}
%
%						\begin{subfigure}[h]{0.45\textwidth}
%							\centering
%							\includegraphics[scale=0.4]{figure_2_1.pdf}
%							\caption{Subcpation number three}
%							\label{sfig:third_subfig}
%						\end{subfigure}
%						\begin{subfigure}[h]{0.45\textwidth}
%							\centering
%							\includegraphics[scale=0.4]{figure_2_2.eps}
%							\caption{Subcpation number four}
%							\label{sfig:fourth_subfig}
%						\end{subfigure}
%						\caption{Here is my main caption describing the relationship between the 4 subimages}
%						\label{fig:main_figure}
%					\end{figure}
%
% 5. You should place your images and figures in a subdirectory.  You can 
%    then tell Latex to look for all your images there using:
%      \graphicspath{{figures/}}
%    Note: you must have both sets of curly braces and include the final
%          directory /
% 
%----------------------------------------------------------------------------
%
% The following is a list of definitions and packages provided by VTthesis:
%
% A. The following packages are provided by the VTthesis class:
%      amsmath, amsthm, amssymb, enumerate, natbib, hyperref, graphicx, 
%      tikz (with shapes and arrows libraries), caption, subcaption.
%      listings, verbatim
%
% B. The following theorem environments are defined by VTthesis:
%      theorem, proposition, lemma, corollary, cojecture
% 
% C. The following definition environments are defined by VTthesis
%      definition, example, remark, algorithm
%
%----------------------------------------------------------------------------
%
%  I hope this template file and the VTthesis class will keep you from having 
%  to worry about the formatting and allow to focus on the actual writing.
%  Good luck and happy writing.
%    Alan Lattimer, VT, 2016
%
%****************************************************************************





